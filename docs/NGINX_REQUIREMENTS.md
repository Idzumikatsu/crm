# NGINX Requirements

## 1. Сбор исходных данных

### 1.1 Ответственный
За аудит отвечает **Ivan Petrov**, SRE Lead.

### 1.2–1.3 Перечень HTTP эндпоинтов
Все текущие сервисы используют HTTP/1.1. Ни WebSocket, ни gRPC не применяются.

| Метод | URI | Протокол |
|-------|-----|----------|
| POST | /api/auth/login | HTTP/1.1 |
| POST | /api/auth/register | HTTP/1.1 |
| GET | /api/groups | HTTP/1.1 |
| GET | /api/groups/{id} | HTTP/1.1 |
| POST | /api/groups | HTTP/1.1 |
| PUT | /api/groups/{id} | HTTP/1.1 |
| DELETE | /api/groups/{id} | HTTP/1.1 |
| GET | /api/hello | HTTP/1.1 |
| GET | /api/lessons | HTTP/1.1 |
| GET | /api/lessons/{id} | HTTP/1.1 |
| POST | /api/lessons | HTTP/1.1 |
| PUT | /api/lessons/{id} | HTTP/1.1 |
| DELETE | /api/lessons/{id} | HTTP/1.1 |
| PATCH | /api/lessons/{id}/status | HTTP/1.1 |
| GET | /api/manager/teachers | HTTP/1.1 |
| GET | /api/manager/students | HTTP/1.1 |
| POST | /api/manager/assign | HTTP/1.1 |
| GET | /api/students | HTTP/1.1 |
| GET | /api/students/{id} | HTTP/1.1 |
| POST | /api/students | HTTP/1.1 |
| PUT | /api/students/{id} | HTTP/1.1 |
| DELETE | /api/students/{id} | HTTP/1.1 |
| GET | /api/teachers | HTTP/1.1 |
| GET | /api/teachers/{id} | HTTP/1.1 |
| POST | /api/teachers | HTTP/1.1 |
| PUT | /api/teachers/{id} | HTTP/1.1 |
| DELETE | /api/teachers/{id} | HTTP/1.1 |
| GET | /api/teacher/lessons | HTTP/1.1 |
| PUT | /api/teacher/lessons/{id} | HTTP/1.1 |
| GET | /api/time-slots | HTTP/1.1 |
| GET | /api/time-slots/{id} | HTTP/1.1 |
| POST | /api/time-slots | HTTP/1.1 |
| PUT | /api/time-slots/{id} | HTTP/1.1 |
| DELETE | /api/time-slots/{id} | HTTP/1.1 |
| GET | /api/users/me | HTTP/1.1 |
| GET | /api/users/{username} | HTTP/1.1 |
| POST | /api/users | HTTP/1.1 |


### 1.4 Метрики нагрузки
Средняя нагрузка приложения оценивается в **50 rps** при пиковых значениях до
**200 rps**. В течение последнего месяца наблюдается стабильный рост около
**10% в неделю**.

### 1.5 Требуемые SLA
- p95 задержки ответа: не более **200&nbsp;мс**;
- p99 задержки ответа: не более **500&nbsp;мс**;
- целевая доступность: **99.9%**.

### 1.6 Требования к защите данных
- логирование без персональных данных (соблюдение GDPR);
- хранение логов не более 30 дней с ограничением доступа;
- всё сетевое взаимодействие должно быть защищено TLS.

### 1.7 Завершение TLS
В текущей топологии TLS не используется. Планируется завершать его на уровне
NGINX.

### 1.8 Распределение обязанностей
- NGINX отвечает за SSL-терминацию, кеш статических ресурсов и ограничения
  скорости;
- приложение реализует аутентификацию, авторизацию и бизнес‑логику;
- правила WAF настраиваются в NGINX.

### 1.9 Консолидация
Настоящий документ фиксирует все выводы этапа сбора данных и используется в
дальнейших шагах по настройке NGINX.


## 2. Проектная топология

### 2.1 Схема сетевых потоков
Трафик от пользователей поступает на контейнер NGINX, который проксирует
его к приложению Spring Boot. Приложение обращается к базе PostgreSQL.
Метрики NGINX экспортируются через отдельный контейнер.

### 2.2 Режим развёртывания
NGINX запускается как отдельный сервис внутри Docker Compose, выполняя роль
общего входного шлюза.

### 2.3 Балансировка трафика
При появлении нескольких экземпляров приложения балансировка будет
осуществляться стандартным алгоритмом `round_robin`.

### 2.4 HTTP/2 и HTTP/3
Клиентские приложения поддерживают HTTP/2. Его подключение планируется на
внешнем интерфейсе NGINX. Переход на HTTP/3 пока не требуется.

### 2.5 Политика релизов
Используется стратегия blue‑green для безрисковых обновлений конфигурации
и приложения.

### 2.6 Целевая архитектура
Принята схема, описанная в `NGINX_DESIGN.md`, которая фиксирует все вышеуказанные
решения.


## 3. Производительность и масштабирование

### 3.1 Рабочие процессы
`worker_processes` установлено в `auto`, что позволяет NGINX использовать все доступные ядра CPU.

### 3.2 Максимум соединений
В директиве `worker_connections` задано значение `1024`, чего достаточно для текущих и прогнозируемых нагрузок.

### 3.3 Политика keep-alive
Тайм-аут соединения ограничен **30&nbsp;с**, максимальное число запросов на одно соединение — **100**.

### 3.4 Сжатие контента
Включён `gzip` для текстовых форматов: HTML, CSS, JSON, JavaScript и XML. Алгоритм сжатия — стандартный gzip с уровнем по умолчанию.

### 3.5 Тайм-ауты проксирования
`proxy_connect_timeout` — **1&nbsp;с**; `proxy_read_timeout` и `proxy_send_timeout` — **5&nbsp;с**.

### 3.6 Базовые ориентиры
- средний ответ сервиса не более **200&nbsp;мс**;
- пиковая нагрузка до **200 rps** выдерживается без деградации;
- масштабирование возможно линейно по числу ядер.

## 4. Безопасность

### 4.1 TLS
Минимальная версия TLS — **1.2**. Разрешены шифры из набора Mozilla Intermediate:
`ECDHE-ECDSA-AES128-GCM-SHA256:ECDHE-RSA-AES128-GCM-SHA256:ECDHE-ECDSA-AES256-GCM-SHA384:ECDHE-RSA-AES256-GCM-SHA384`.

### 4.2 HSTS и статус сертификатов
Добавлен заголовок `Strict-Transport-Security` со сроком 63072000 секунд и включён
`ssl_stapling` вместе с `ssl_stapling_verify` для проверки актуальности сертификатов.

### 4.3 Ограничение скорости
С помощью `limit_req_zone` и `limit_req` ограничено до **10 rps** с буфером в **20** запросов на одного клиента.

### 4.4 WAF
Используются правила ModSecurity из набора **OWASP Core Rule Set** версии 4, перекрывающие
основные пункты OWASP Top‑10. Конфигурация позволяет легко дополнять её кастомными
регулярными выражениями при обнаружении специфических атак.

### 4.5 Размер тела запроса
Базовое ограничение `client_max_body_size` установлено на **1&nbsp;МБ**. Для путей,
где ожидаются крупные загрузки файлов, лимит может быть увеличен локально до **10&nbsp;МБ**.

### 4.6 Контрольный лист
Перед выводом в эксплуатацию выполняются проверки из файла
`SECURITY_CHECKLIST.md`, включая валидацию сертификатов, загрузку WAF и
актуальность настроек логирования.

## 5. Кеширование и статика

### 5.1 Классификация путей
- **Статический контент** — файлы в `/static/`, `/favicon.ico` и ресурсы с
  расширениями `.css`, `.js`, `.png`, `.jpg`, `.jpeg`, `.gif`, `.svg`.
- **Динамические API‑ресурсы** — все запросы под `/api/**`.

### 5.2 Версионные ассеты
Статические файлы получают имена вида `app.[hash].js` или `style.[hash].css`.
Хеш добавляется на этапе сборки, что позволяет задавать длительный срок кеша
без риска выдачи устаревшего содержимого.

### 5.3 Сроки кэширования статики
Для статических ресурсов отправляется заголовок
`Cache-Control: public, max-age=2592000, immutable` (30 дней). Динамические
GET-запросы кешируются в NGINX не более **5&nbsp;минут**.

### 5.4 Кратковременный кеш публичных GET
В локации `/api/` включён `proxy_cache` с валидностью 5&nbsp;минут. Это снижает
нагрузку на приложение при высокочастотных запросах.

### 5.5 Инвалидирование кеша
При развёртывании новой версии генерируются ассеты с новым хешем и выполняется
`nginx -s reload`, что очищает внутренний кеш NGINX.

## 6. Долгоживущие соединения

### 6.1 Перечень эндпоинтов
Текущая версия приложения не использует WebSocket или Server-Sent Events.

### 6.2 Тайм-ауты чтения
При появлении долгоживущих соединений `proxy_read_timeout` должен быть не менее **60 минут**.

### 6.3 Повторные подключения
При обрыве соединения клиент повторяет запрос с экспоненциальной задержкой. NGINX не выполняет автоматический ретрай.

## 7. Наблюдаемость и логирование

### 7.1 Формат логов
Все access и error логи пишутся в формате JSON.

### 7.2 Доставка логов
Логи передаются на stdout контейнера и собираются Fluent Bit в Elastic.

### 7.3 Метрики
Экспорт из `stub_status` отдаётся в Prometheus. Основные метрики: число запросов, время отклика, доля 4xx/5xx.

### 7.4 Пороговые алерты
Алерт срабатывает при доле 5xx > 1% за 5 минут, p99 > 500мс и проблемах upstream.

### 7.5 Диагностика инцидентов
Сценарии описаны в `docs/RUNBOOK_NGINX.md`.
